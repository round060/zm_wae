---
title: "EF_WAE_ZM_Model1"
author: "Holly Kundel"
date: "11/15/2021"
output: html_document
---

This model is run using `ZM_LAKE` as zebra mussel invasion variable - Only considered invaded if at least one EF survey was done the year of invasion or later - No invasions after 2019 count (because no data post 2019) - "0" indicates a lake is uninvaded (based on above criteria) - "1" indicates a lake is invaded (based on above criteria)

Load in Required Packages

```{r}
#remove.packages(c("StanHeaders", "rstan"))
#install.packages("rstan", repos = c('https://stan-dev.r-universe.dev', getOption("repos")))
#if (file.exists(".RData")) file.remove(".RData")
#This one works best?
#install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
library("rstan") # observe startup messages
library(readr)
library(dplyr)
library(tidyr)
library(lubridate)
library(stringr)
library(arm)
library(doBy)
library(sf)
library(spData)
library(RANN)
library(ggplot2)
library(MASS)
library(bayesplot)
```

Load in Data

```{r, message=FALSE}
dat <- read_csv("./cleaned_data/year_3_fish_lake_age_alk.csv") %>% 
  mutate(survey_id = row_number()) %>% drop_na()

unique(dat$lake.id)


with(dat, hist(age3_count), breaks = 1000)
nrow(dat[dat$age3_count==0,])/nrow(dat)
```

# Nearest Neighbor Code

-   Assigning uninvaded lakes a "pseudo-invasion year" for BACI set up

Data setup
Create Spatial sf Object

```{r}
# Create spatial sf object (4326 = WGS84)
dat.geo <- st_as_sf(dat, coords = c("x", "y"), crs = 4326)
```

Separate Invaded Lakes and Uninvaded Lakes

-   Using column `ZM_LAKE` for this
-   Only considered invaded if at least one EF survey was done the year of invasion or later
-   
-   "0" indicates a lake is uninvaded (based on above criteria)
-   "1" indicates a lake is invaded (based on above criteria)

```{r}
dat.geo.uninvaded <- dat.geo %>% 
  filter(year_confirmed == 0)
dim(dat.geo.uninvaded) 

dat.geo.invaded <- dat.geo %>% 
  filter(year_confirmed > 0)
dim(dat.geo.invaded) 
```

Get coordinate matrices

```{r}
uninvaded_coords <- do.call(rbind, st_geometry(dat.geo.uninvaded))
invaded_coords <- do.call(rbind, st_geometry(dat.geo.invaded))
invaded_coords <- cbind(invaded_coords, 1:nrow(invaded_coords)) # Index for identifying nearest lake

```

Find nearest neighbor

```{r}
closest <- nn2(invaded_coords[,1:2], uninvaded_coords,  k = 1, searchtype = "standard")
#str(closest)
#head(closest)
closest <- sapply(closest, cbind) 
```

Combine uninvaded data with nearest neighbor assignments

```{r}
dat.geo.uninvaded <- cbind(dat.geo.uninvaded, closest)
dim(dat.geo.uninvaded) 
```

Give invaded lakes an identifier and select columns

```{r}
dat.geo.invaded$nn.idx <- 1:nrow(dat.geo.invaded)
dat.geo.invaded <- dat.geo.invaded %>% 
  dplyr::select(year_confirmed, nn.idx)
head(dat.geo.invaded)

#str(dat.geo.uninvaded)
#str(dat.geo.invaded)
```

Merge uninvaded with invaded `YEAR_INFESTED` for use as "after" year in BACI (Before After Control Impact)

```{r}
dat.geo.invaded_merge <- st_set_geometry(dat.geo.invaded, NULL)

dat.geo.uninvaded.final <- dat.geo.uninvaded %>%
    left_join(dat.geo.invaded_merge, by = c("nn.idx"))
str(dat.geo.uninvaded.final)
summary(dat.geo.uninvaded.final)
# Bring back into full dataset
# Convert to dataframe
dat.geo.uninvaded.final.df <- st_set_geometry(dat.geo.uninvaded.final, NULL)
class(dat.geo.uninvaded.final.df)
str(dat.geo.uninvaded.final.df)

# Join dat.geo.uninvaded.final.df - want YEAR_INFESTED.y - with original data, dat
# Grab columns of interest
dat.geo.uninvaded.final.df <- dat.geo.uninvaded.final.df %>% 
  dplyr::select(survey_id, year_confirmed.y)
dim(dat.geo.uninvaded.final.df)
head(dat.geo.uninvaded.final.df)
dim(dat)

# Final merge
final.dat3 <- dat %>%
    left_join(dat.geo.uninvaded.final.df, by = c("survey_id"))
dim(final.dat3)
head(final.dat3)
```


# Prepare to run model

Load more libraries

```{r}
# if you need to install stan run: "install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)"
#library(StanHeaders)
library(rstan)
library(bayesplot)
library(lme4)
library(ggmcmc) # Use ggmcmc package for assessing convergence
library(gridExtra)
library(ggthemes)
library(coda)
library(forcats)
```


```{r}
dat <- final.dat3 %>%
  mutate(ZM_LAKE = ifelse(year_confirmed == 0, 0, 1),
         log_acres = log(acres),
         fry.pa = FRY/acres,
         fgl.pa = FGL/acres)

```

Create BACI design variables

```{r}
# "Treatment" is lake-level invasion status, ZM (1 = ZM; 0 otherwise)
# Before/After time variable ("post" = 1 if sampled after invasion; 0 if before)
# Below, "year" is year of sampling and time is year infested
dat <- dat %>% 
  mutate(time = ifelse(year_confirmed == 0, year_confirmed.y, year_confirmed),
         post = ifelse(birth.year >= time, 1, 0),
         treatment = ZM_LAKE # USING ZM_LAKE_HERE
         )%>%
  mutate(INVASION_STATUS_NEW = case_when(ZM_LAKE == 0 ~ "Uninvaded",
                                         ZM_LAKE == 1 & post == 0 ~ "PRE_ZM",
                                         ZM_LAKE == 1 & post == 1 ~ "POST_ZM"))


#check data
dat %>%
  group_by(ZM_LAKE) %>%  
  count(post, ZM_LAKE) %>%
  ungroup() %>% 
  mutate(prop = prop.table(n))

###new addition of data filtering#######
#ensure at least one year pre and post
test = dat %>% 
  group_by(lake.id, post, ZM_LAKE) %>% 
  summarise(count=n()) %>% 
  filter(count>0) %>% ungroup() %>% 
  group_by(lake.id, ZM_LAKE) %>% 
  summarise(pre.post.test=n()) %>% 
  filter(pre.post.test==2)


dat <- dat %>% filter(lake.id %in% test$lake.id)
```

Prep for model

```{r}
# Create lake ID
dat$lake.id <- as.numeric(as.factor(as.numeric(as.factor(dat$lake.id))))
# Create year ID
dat$year.id <- as.numeric(as.factor(as.numeric(as.factor(dat$year))))
nyear <- length(unique(dat$year.id))

# Sort data by site
dat <- dat %>% 
  arrange(lake.id)

# Effort offset term (maybe multiply eff_seconds by the number_of_netters?)
dat <- dat %>% 
  mutate(offsets = log(total.effort.1))
```

Lake-level predictors

```{r}
# Prepare lake-level predictors
lake_area <- summaryBy(log_acres ~ lake.id, data=dat, FUN=mean)
gdd <- summaryBy(median_gdd_5 ~ lake.id, data=dat, FUN=mean)


# Transform as needed and scale
lake_area2 <- as.numeric(scale(log(lake_area$log_acres.mean)))
gdd2 <- as.numeric(scale(gdd$median_gdd_5.mean))
#secchi2 <- as.numeric(scale(secchi$median_secchi.mean))
```

Observation-level predictors

```{r}
# Observation-level predictors, transform as needed and scale
#anomaly_gdd_year0 <- as.numeric(scale(dat$gdd_wtr_5c_anomaly_year0))
#anomaly_gdd_year1 <- as.numeric(scale(dat$gdd_wtr_5c_anomaly_year1))
#anomaly_gdd_year2 <- as.numeric(scale(dat$gdd_wtr_5c_anomaly_year2))
#anomaly_gdd_year3 <- as.numeric(scale(dat$gdd_wtr_5c_anomaly_year3))
sum <- (dat$gdd_wtr_5c_year0 + dat$gdd_wtr_5c_year1 + dat$gdd_wtr_5c_year2) - (3*dat$median_gdd_5)

gdd_sum <- as.numeric(scale(sum))

fry.pa <- as.numeric(scale(dat$fry.pa))
fgl.pa <- as.numeric(scale(dat$fgl.pa))


post <- dat$post
x.treatment <- dat$treatment

```

Quick test with glmer

```{r}
m0 <-glmer(age3_count~ 1 + (1 | lake.id), data = dat, family = poisson(link = "log"), nAGQ = 100)
#summary(m0)
# # 
m1 <- glmer(age3_count ~ post + treatment + post*treatment + (1|lake.id), nAGQ = 100,
             data=dat, family = poisson(link="log"))
#summary(m1)
#performance::check_zeroinflation(m1)
```

Export data with correct number of observations and scaled variables

```{r}
dat$gdd_sum_S <- gdd_sum
dat$fry.pa_S <- fry.pa
dat$fgl.pa_S <- fgl.pa

temp_gdd2 = as.data.frame(gdd2) %>% rowid_to_column() %>% rename(gdd_S = gdd2)
temp_area = as.data.frame(lake_area2) %>% rowid_to_column() %>% rename(area_S = lake_area2)

dat <- merge(x = dat, y = temp_gdd2, by.x = c("lake.id"), by.y = c("rowid")) %>% 
  merge(y = temp_area, by.x = c("lake.id"), by.y = c("rowid"))

#write.csv(dat, "./cleaned_data/gn_model_data.csv", row.names = F)
```


Check that data is in correct form
```{r}
n_post <- max(post)
n_trt <- max(x.treatment)
n_lake <- max(dat$lake.id)
n_year <- max(dat$year.id)


```

Load data; x = x; (dim(x)[2] + dim(x_obs)[2] + 1)

```{r}
data <- list(y = dat$age3_count, lake = dat$lake.id, N = dim(dat)[1], 
             n_lake = n_lake, offsets=dat$offsets, 
             year = dat$year.id, n_year = n_year, n_post = n_post, n_trt = n_trt,
             post = post, trt = x.treatment, 
             fry_pa = fry.pa, fgl_pa = fgl.pa,
             survey_gdd_sum = gdd_sum, 
             gdd = gdd2, lake_area = lake_area2 # variables with 2 at the end are "lake level" predictors
             ) 
```



```{r}
options(scipen = 999)
out <- stan(file='./pois_model_zip3_GN.stan', data = data,
            iter = 50000, warmup = 20000, chains=4, thin=1, cores=4, refresh = 1)
print(out)


# Save all the stan output
#
saveRDS(out, file="./models/model_out_zip_GN_nosecchi_3gddanomalyCR.rds")
#out <- readRDS(file="./models/model_out_zip_GN_nosecchi_3gddanomalyCR.rds")
summary(out)

mcmc_trace(out, pars = c("sigma_year", "sigma_lake", "theta", 
                         "b_0", "b_post", "b_trt",  "b_post_trt", "b_fry", "b_fry", "b_fgl", "b_lake_area"))
```
